cd(@__DIR__)
using Pkg
Pkg.activate(".")

using Flux: gradient
using LinearAlgebra
using Random
using RobustNeuralNetworks


# DirectRENParams
ρ = [3.1622777]
X = [-0.3432368  -0.31381652  -0.19065112   0.5247829  -0.1795016   0.08251798 -0.06806514 -0.03736481 -0.47246554  0.4513094;
      0.4248231   0.46738613 -0.45483816  -0.00164843 -0.33090267 -0.41798478  0.0721586   0.01275089 -0.10325089  0.3065241;
     -0.25544098  0.280061    0.33097017  -0.04983602 -0.31211174  0.05645915 -0.05503957 -0.6882003   0.28305843  0.29481986;
     -0.22278021  0.11286005  0.24806102   0.43213546 -0.08487444 -0.6571174  -0.0569835  -0.03449053 -0.07330114 -0.49044806;
     -0.22577527  0.22928512  0.45739192  -0.13572325 -0.41283894  0.06258066  0.1832785   0.64859164 -0.04739126  0.1948465;
      0.6205935  -0.3672491   0.41051123   0.15953851 -0.25277862 -0.03628886 -0.44993392  0.02993932  0.06610987  0.11444864;
     -0.15473649  0.3029188  -0.22447734  -0.11396175 -0.27293447  0.319251   -0.6927757   0.05441964 -0.20189461 -0.34762588;
     -0.01548782 -0.11554869 -0.32180318   0.41438186 -0.38959715  0.24189702  0.17797166  0.13438153  0.64122343 -0.19984755;
     -0.35354054 -0.27301002 -0.20356381  -0.29731077  0.07180007 -0.44884998 -0.4117119   0.201592    0.40894675  0.29434273;
      0.03934382  0.4741397   0.11219003   0.46734247  0.5365609   0.12788108 -0.25832778  0.20101154  0.23417431  0.27644217]
B2 = reshape([-1.4166749; -0.61229825; 1.3889176], 3, 1)
D12 = reshape([-0.39930755; 0.23696136; -0.01424979; -0.43245763], 4, 1)
Y1 = [-0.6045977  -0.56866693 -0.77085614;
      -0.37148985  0.6452562   0.15128379;
       0.16694038  0.6938009   0.54838187]
C2 = [ 0.2398148   0.30443615 -0.95625865;
       0.2550661   0.49206418  0.91056406]
D21 = [ 1.084308    0.37685412 -0.23596834  0.4871412;
        0.33572176  0.44341874  1.0918796   0.15586945]
D22 = reshape([1.1305465; 0.78321606], 2, 1)
X3 = reshape([1.0], 1, 1)
Y3 = reshape([0.0], 1, 1)
Z3 = reshape([0.0], 1, 1)
bx = [ 0.21667565,  0.26124063, -1.1558732]
bv = [-0.5839606,  -0.13565616,  0.33354622,  0.6612388]
by = [-0.25244614, -0.94863135]


T = Float32
ϵ = T(1e-12)

direct_ps = DirectRENParams{T}(
    X, 
    Y1, X3, Y3, Z3, 
    B2, C2, D12, D21, D22,
    bx, bv, by, ϵ, ρ,
    true, true, false,
    false
)
nu, nx, nv, ny = 1, 3, 4, 2
γ = 10
ren_ps = LipschitzRENParams{T}(tanh, nu, nx, nv, ny, direct_ps, T(0.5), [γ], false)
ren = REN(ren_ps)

batches = 4
rng = Xoshiro(42)
x0 = init_states(ren, batches; rng) .+ 1
u0 = ones(ren.nu, batches)

# Evaluate the REN over one timestep
x1, y1 = ren(x0, u0)
println(x1)
println(y1)

function loss(states, inputs)
    model = REN(ren_ps)
    nstate, out = model(states, inputs)
    return sum(nstate.^2) + sum(out.^2)
end

gs = gradient(loss, x0, u0)
println(loss(x0, u0))
println("States grad: ", gs[1])
println("Output grad: ", gs[2])
